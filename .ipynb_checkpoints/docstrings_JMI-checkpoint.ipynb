{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing docstrings for functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Writing-docstrings-for-functions\" data-toc-modified-id=\"Writing-docstrings-for-functions-1\">Writing docstrings for functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Template\" data-toc-modified-id=\"Template-1.1\">Template</a></span></li><li><span><a href=\"#DATA-I/O\" data-toc-modified-id=\"DATA-I/O-1.2\">DATA I/O</a></span></li><li><span><a href=\"#TESTING_DATASET\" data-toc-modified-id=\"TESTING_DATASET-1.3\">TESTING_DATASET</a></span></li><li><span><a href=\"#EDA-/-DF-INSPECTION\" data-toc-modified-id=\"EDA-/-DF-INSPECTION-1.4\">EDA / DF INSPECTION</a></span><ul class=\"toc-item\"><li><span><a href=\"#PANDAS-STYLING\" data-toc-modified-id=\"PANDAS-STYLING-1.4.1\">PANDAS STYLING</a></span></li></ul></li><li><span><a href=\"#James'-Tree-Classifier/Regressor-Testing-&amp;-Visualization\" data-toc-modified-id=\"James'-Tree-Classifier/Regressor-Testing-&amp;-Visualization-1.5\">James' Tree Classifier/Regressor Testing &amp; Visualization</a></span></li><li><span><a href=\"#Outlier-Detection-and-Stats-tests\" data-toc-modified-id=\"Outlier-Detection-and-Stats-tests-1.6\">Outlier Detection and Stats tests</a></span></li><li><span><a href=\"#Mike's-Plotting-Functions\" data-toc-modified-id=\"Mike's-Plotting-Functions-1.7\">Mike's Plotting Functions</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Breif description.\n",
    "Usage example.\n",
    "Parameters:\n",
    "-----------\n",
    "args: type, shape if applicable\n",
    "\tAs necesary a description as needed.\n",
    "**kwargs: dicts\n",
    "\t\tbrief descript.\n",
    "Returns:\n",
    "----------\n",
    "what is returns : type\n",
    "\tbrief descrip. if nec.\n",
    "\n",
    "\"\"\" \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT HEADERS AND DATAFRAMES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import scipy.stats as sts\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_dict = {'pandas':'pd',\n",
    "                 'numpy':'np',\n",
    "                 'matplotlib':'mpl',\n",
    "                 'matplotlib.pyplot':'plt',\n",
    "                 'seaborn':'sns',\n",
    "                 'scip.stats.':'sts',\n",
    "                 }\n",
    "# index_range = list(range(1,len(import_dict)))\n",
    "df_imported= pd.DataFrame.from_dict(import_dict,orient='index')\n",
    "df_imported.columns=['Module/Package Handle']\n",
    "list_packages = df_imported.index\n",
    "df_imported.reset_index(inplace=True)\n",
    "df_imported.columns=['Imported Module/Package','Imported As']\n",
    "# inspect_df(df)\n",
    "function_list = ['color_true_rlist2df','df_drop_regex','viz_tree','performance_r2_mse','performance_roc_auc',\n",
    "'performance_roc_auc','tune_params_trees','multiplot','plot_hist_ scat_sns','detect_outliers','describe_outliers','Cohen_d',\n",
    "'draw_violinplot','subplot_imshow','plot_wide_kde_thin_bar','confusion_matrix','scale_data']\n",
    "excluded='plot_pdf'\n",
    "function_series = pd.DataFrame(function_list)\n",
    "function_series.columns=['List of Available Functions']\n",
    "# function_series.Name='Package_Functions'\n",
    "# display(function_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imported.set_index('Imported Module/Package',inplace=True)\n",
    "from IPython.display import HTML\n",
    "pd.set_option('display.precision',3)\n",
    "pd.set_option('display.html.border',2)\n",
    "# pd.set_option('display.notebook_repr_htm',True)\n",
    "pd.set_option('display.max_columns',None)\n",
    "# pd.set_option('display.html.table_schema',True)\n",
    "\n",
    "CSS_new=\"\"\"\n",
    ".{\n",
    "text-align: center;\n",
    "}\n",
    "th{\n",
    "background-color: black;\n",
    "color: white;\n",
    "font-family:serif;\n",
    "font-size:1.2em;\n",
    "}\n",
    "td{\n",
    "font-size:0.9em\n",
    "}\n",
    "td, th{\n",
    "text-align: center;\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "CSS = \"\"\"\n",
    "table.dataframe td, table.dataframe th { /* This is for the borders for columns)*/\n",
    "    border: 2px solid black\n",
    "    border-collapse:collapse;\n",
    "    text-align:center;\n",
    "}\n",
    "table.dataframe th {\n",
    "    /*padding:1em 1em;*/\n",
    "    background-color: #000000;\n",
    "    color: #ffffff;\n",
    "    text-align: center;\n",
    "    font-weight: bold;\n",
    "    font-size: 12pt\n",
    "    font-weight: bold;\n",
    "    padding: 0.5em 0.5em;\n",
    "}\n",
    "table.dataframe td:not(:th){\n",
    "    /*border: 1px solid ##e8e8ea;*/\n",
    "    /*background-color: ##e8e8ea;*/\n",
    "    background-color: gainsboro;\n",
    "    text-align: center; \n",
    "    vertical-align: middle;\n",
    "    font-size:10pt;\n",
    "    padding: 0.7em 1em;\n",
    "    /*padding: 0.1em 0.1em;*/\n",
    "}\n",
    "table.dataframe tr:not(:last-child) {\n",
    "    border-bottom: 1px solid gainsboro;\n",
    "}\n",
    "table.dataframe {\n",
    "    /*border-collapse: collapse;*/\n",
    "    background-color: gainsboro; /* This is alternate rows*/\n",
    "    text-align: center;\n",
    "    border: 2px solid black;\n",
    "}\n",
    "table.dataframe th:not(:empty), table.dataframe td{\n",
    "    border-right: 1px solid white;\n",
    "    text-align: center;\n",
    "}\n",
    "\"\"\"\n",
    "# HTML('<style>.output {flex-direction: row;}</style>')\n",
    "\n",
    "def html_off():\n",
    "    HTML(\"<style></style>\")\n",
    "def html_on(CSS):\n",
    "    HTML(f'<style>{CSS}</style>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA I/O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_for_user = True \n",
    "\n",
    "\n",
    "fig_filepath = \"Figures/\"\n",
    "data_filepath = \"Exported CSV/\"\n",
    "def export_data(df_table,table_name):\n",
    "    import time \n",
    "\n",
    "    data_filepath = \"Exported CSV/\"\n",
    "    df_table.round(4).to_csv(data_filepath+table_name+'.csv')\n",
    "    time.sleep(1)\n",
    "    df_table.round(4).to_excel(data_filepath+table_name+'.xlsx')\n",
    "    df_table.round(4).to_html(data_filepath+table_name+'.html')\n",
    "    time.sleep(1)\n",
    "    df2png(df_table,table_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/jirvingphd/dsc-1-final-project-online-ds-ft-021119/master/kc_house_data.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed date.\n",
      "Removed room.\n",
      "Removed sqft.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"2\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.511</td>\n",
       "      <td>-122.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.721</td>\n",
       "      <td>-122.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.738</td>\n",
       "      <td>-122.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.521</td>\n",
       "      <td>-122.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.617</td>\n",
       "      <td>-122.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     price  floors  waterfront  view  condition  grade  yr_built  \\\n",
       "0  7129300520  221900.0     1.0         NaN   0.0          3      7      1955   \n",
       "1  6414100192  538000.0     2.0         0.0   0.0          3      7      1951   \n",
       "2  5631500400  180000.0     1.0         0.0   0.0          3      6      1933   \n",
       "3  2487200875  604000.0     1.0         0.0   0.0          5      7      1965   \n",
       "4  1954400510  510000.0     1.0         0.0   0.0          3      8      1987   \n",
       "\n",
       "   yr_renovated  zipcode     lat     long  \n",
       "0           0.0    98178  47.511 -122.257  \n",
       "1        1991.0    98125  47.721 -122.319  \n",
       "2           NaN    98028  47.738 -122.233  \n",
       "3           0.0    98136  47.521 -122.393  \n",
       "4           0.0    98074  47.617 -122.045  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[:100]\n",
    "df_cut = drop_cols(df,['date','room','sqft'])\n",
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA / DF INSPECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inspect_df(df,n_rows=2):\n",
    "#     \"\"\"Displays df.head(),df.info(),df.describe() for dataframe. \n",
    "#     Ex: inspect_df(df)\"\"\"\n",
    "#     pd.set_option('display.precision',3)\n",
    "#     pd.set_option('display.html.border',2)\n",
    "#     pd.set_option('display.notebook_repr_htm',True)\n",
    "#     display(df.head(n_rows))\n",
    "#     display(df.info()), display(df.describe())\n",
    "\n",
    "# def list2df(list):#, sort_values='index'):\n",
    "#     \"\"\" Take a list where each row becomes a dataframe row and the row[0] contains the columns names.\n",
    "#     Ex: list_results = [[\"Test\",\"N\",\"p-val\"]] #... (some sort of analysis performed to produce results)\n",
    "#         list_results.append([test_Name,length(data),p])\n",
    "#         list2df(list_results)\n",
    "#     \"\"\"    \n",
    "#     df_list = pd.DataFrame(list[1:],columns=list[0])        \n",
    "#     return df_list\n",
    "\n",
    "# def drop_cols(df, list_of_strings_or_regexp):#,axis=1):\n",
    "#     \"\"\"Take a df, a list of strings or regular expression and recursively \n",
    "#     removes all matching column names containing those strings or expressions.\n",
    "#     # Example: if the df_in columns are ['price','sqft','sqft_living','sqft15','sqft_living15','floors','bedrooms']\n",
    "#     df_out = drop_cols(df_in, ['sqft','bedroom'])\n",
    "#     df_out.columns # will output: ['price','floors']\n",
    "    \n",
    "#     Parameters:\n",
    "#         DF -- input dataframe to remove columns from.\n",
    "#         regex_list -- list of string patterns or regexp to remove.\n",
    "    \n",
    "#     Returns:\n",
    "#         df_dropped -- input df without the dropped columns. \n",
    "#     \"\"\"\n",
    "#     regex_list=list_of_strings_or_regexp\n",
    "#     df_cut = df.copy()\n",
    "#     for r in regex_list:\n",
    "#         df_cut = df_cut[df_cut.columns.drop(list(df_cut.filter(regex=r)))]\n",
    "#         print(f'Removed {r}.')\n",
    "#     df_dropped = df_cut\n",
    "#     return df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MULTIPLOT\n",
    "# def multiplot(df):\n",
    "#     \"\"\"Plots results from df.corr() in a correlation heat map for multicollinearity.\n",
    "#     Returns fig, ax objects\"\"\"\n",
    "#     import seaborn as sns\n",
    "#     sns.set(style=\"white\")\n",
    "#     from string import ascii_letters\n",
    "#     import numpy as np\n",
    "#     import pandas as pd\n",
    "#     import seaborn as sns\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#     # Compute the correlation matrix\n",
    "#     corr = df.corr()\n",
    "\n",
    "#     # Generate a mask for the upper triangle\n",
    "#     mask = np.zeros_like(corr, dtype=np.bool)\n",
    "#     mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "#     # Set up the matplotlib figure\n",
    "#     f, ax = plt.subplots(figsize=(16, 16))\n",
    "\n",
    "#     # Generate a custom diverging colormap\n",
    "#     cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "#     # Draw the heatmap with the mask and correct aspect ratio\n",
    "#     sns.heatmap(corr, mask=mask, annot=True, cmap=cmap, center=0,\n",
    "                \n",
    "#     square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "#     return f, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plots histogram and scatter (vs price) side by side\n",
    "# def plot_hist_scat(df, target='index'):\n",
    "#     \"\"\"Plots seaborne distplots and regplots for columns im datamframe vs target.\n",
    "\n",
    "#     Parameters:\n",
    "#     df (DataFrame): DataFrame.describe() columns will be used. \n",
    "#     target = name of column containing target variable.assume first coluumn. \n",
    "    \n",
    "#     Returns:\n",
    "#     Figures for each column vs target with 2 subplots.\n",
    "#    \"\"\"\n",
    "#     import matplotlib.ticker as mtick\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import seaborn as sns\n",
    "    \n",
    "#     with plt.style.context(('dark_background')):\n",
    "#         ###  DEFINE AESTHETIC CUSTOMIZATIONS  -------------------------------##\n",
    "#         figsize=(14,10)\n",
    "\n",
    "#         # Axis Label fonts\n",
    "#         fontTitle = {'fontsize': 16,\n",
    "#                    'fontweight': 'bold',\n",
    "#                     'fontfamily':'serif'}\n",
    "\n",
    "#         fontAxis = {'fontsize': 14,\n",
    "#                    'fontweight': 'bold',\n",
    "#                     'fontfamily':'serif'}\n",
    "\n",
    "#         fontTicks = {'fontsize': 12,\n",
    "#                    'fontweight':'bold',\n",
    "#                     'fontfamily':'serif'}\n",
    "\n",
    "#         # Formatting dollar sign labels\n",
    "#         # fmtPrice = '${x:,.0f}'\n",
    "#         # tickPrice = mtick.StrMethodFormatter(fmtPrice)\n",
    "\n",
    "\n",
    "#         ###  PLOTTING ----------------------------- ------------------------ ##\n",
    "\n",
    "#         # Loop through dataframe to plot\n",
    "#         for column in df.describe():\n",
    "\n",
    "#             # Create figure with subplots for current column\n",
    "#             fig, ax = plt.subplots(figsize=figsize, ncols=2, nrows=2)\n",
    "\n",
    "#             ##  SUBPLOT 1 --------------------------------------------------##\n",
    "#             i,j = 0,0\n",
    "#             ax[i,j].set_title(column.capitalize(),fontdict=fontTitle)\n",
    "\n",
    "#             # Define graphing keyword dictionaries for distplot (Subplot 1)\n",
    "#             hist_kws = {\"linewidth\": 1, \"alpha\": 1, \"color\": 'steelblue','edgecolor':'w','hatch':'\\\\'}\n",
    "#             kde_kws = {\"color\": \"white\", \"linewidth\": 3, \"label\": \"KDE\",'alpha':0.7}\n",
    "\n",
    "#             # Plot distplot on ax[i,j] using hist_kws and kde_kws\n",
    "#             sns.distplot(df[column], norm_hist=True, kde=True,\n",
    "#                          hist_kws = hist_kws, kde_kws = kde_kws,\n",
    "#                          label=column+' histogram', ax=ax[i,j])\n",
    "\n",
    "\n",
    "#             # Set x axis label\n",
    "#             ax[i,j].set_xlabel(column.title(),fontdict=fontAxis)\n",
    "\n",
    "#             # Get x-ticks, rotate labels, and return\n",
    "#             xticklab1 = ax[i,j].get_xticklabels(which = 'both')\n",
    "#             ax[i,j].set_xticklabels(labels=xticklab1, fontdict=fontTicks, rotation=0)\n",
    "#             ax[i,j].xaxis.set_major_formatter(mtick.ScalarFormatter())\n",
    "\n",
    "\n",
    "#             # Set y-label \n",
    "#             ax[i,j].set_ylabel('Density',fontdict=fontAxis)\n",
    "#             yticklab1=ax[i,j].get_yticklabels(which='both')\n",
    "#             ax[i,j].set_yticklabels(labels=yticklab1,fontdict=fontTicks)\n",
    "#             ax[i,j].yaxis.set_major_formatter(mtick.ScalarFormatter())\n",
    "\n",
    "\n",
    "#             # Set y-grid\n",
    "#             ax[i, j].set_axisbelow(True)\n",
    "#             ax[i, j].grid(axis='y',ls='--')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             ##  SUBPLOT 2-------------------------------------------------- ##\n",
    "#             i,j = 0,1\n",
    "#             ax[i,j].set_title(column.capitalize(),fontdict=fontTitle)\n",
    "\n",
    "#             # Define the kwd dictionaries for scatter and regression line (subplot 2)\n",
    "#             line_kws={\"color\":\"white\",\"alpha\":0.5,\"lw\":3,\"ls\":\":\"}\n",
    "#             scatter_kws={'s': 2, 'alpha': 0.8,'marker':'.','color':'steelblue'}\n",
    "\n",
    "#             # Plot regplot on ax[i,j] using line_kws and scatter_kws\n",
    "#             sns.regplot(df[column], df[target], \n",
    "#                         line_kws = line_kws,\n",
    "#                         scatter_kws = scatter_kws,\n",
    "#                         ax=ax[i,j])\n",
    "\n",
    "#             # Set x-axis label\n",
    "#             ax[i,j].set_xlabel(column.title(),fontdict=fontAxis)\n",
    "\n",
    "#              # Get x ticks, rotate labels, and return\n",
    "#             xticklab2=ax[i,j].get_xticklabels(which='both')\n",
    "#             ax[i,j].set_xticklabels(labels=xticklab2,fontdict=fontTicks, rotation=0)\n",
    "#             ax[i,j].xaxis.set_major_formatter(mtick.ScalarFormatter())\n",
    "\n",
    "#             # Set  y-axis label\n",
    "#             ax[i,j].set_ylabel(target.title(),fontdict=fontAxis)\n",
    "\n",
    "#             # Get, set, and format y-axis Price labels\n",
    "#             yticklab = ax[i,j].get_yticklabels()\n",
    "#             ax[i,j].set_yticklabels(yticklab,fontdict=fontTicks)\n",
    "#             ax[i,j].yaxis.set_major_formatter(mtick.ScalarFormatter())\n",
    "\n",
    "#             # Set y-grid\n",
    "#             ax[i, j].set_axisbelow(True)\n",
    "#             ax[i, j].grid(axis='y',ls='--')       \n",
    "\n",
    "#             ## ---------- Final layout adjustments ----------- ##\n",
    "#             # Deleted unused subplots \n",
    "#             fig.delaxes(ax[1,1])\n",
    "#             fig.delaxes(ax[1,0])\n",
    "\n",
    "#             # Optimizing spatial layout\n",
    "#             fig.tight_layout()\n",
    "#             # figtitle=column+'_dist_regr_plots.png'\n",
    "#             # plt.savefig(figtitle)\n",
    "#     return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PANDAS STYLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ## hover_\n",
    "# def hover(hover_color=\"gold\"):\n",
    "#     from IPython.display import HTML\n",
    "#     return dict(selector=\"tr:hover\",\n",
    "#                 props=[(\"background-color\", \"%s\" % hover_color)])\n",
    "# def highlight(df,hover_color=\"gold\"):\n",
    "#     styles = [\n",
    "#         hover(hover_color),\n",
    "#         dict(selector=\"th\", props=[(\"font-size\", \"115%\"),\n",
    "#                                    (\"text-align\", \"center\")]),\n",
    "#         dict(selector=\"caption\", props=[(\"caption-side\", \"bottom\")])\n",
    "#     ]\n",
    "#     html = (df.style.set_table_styles(styles)\n",
    "#               .set_caption(\"Hover to highlight.\"))\n",
    "#     return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def color_true_green(val):\n",
    "#     \"\"\"Changes text color to green if value is True\n",
    "#     Ex: style_df = df.style.applymap(color_true_green)\n",
    "#         style_df #to display\"\"\"\n",
    "#     color='green' if val==True else 'black'\n",
    "#     return f'color: {color}' \n",
    "\n",
    "# # Style dataframe for easy visualization\n",
    "# def color_scale_columns(df,matplotlib_cmap = \"Greens\",subset=None,):\n",
    "#     \"\"\"\n",
    "#     Takes a df, any valid matplotlib colormap column names(matplotlib.org/tutorials/colors/colormaps.html) \n",
    "#     and returns a dataframe with a gradient colormap applied to column values.\n",
    "#     Ex. color_scale_columns(df,\"YlGn\")\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     df: DataFrame containing columns to style.\n",
    "#     subset: Names of columns to color-code.\n",
    "#     cmap: Any matplotlib colormap. https://matplotlib.org/tutorials/colors/colormaps.html\n",
    "#     Colormap to use instead of default seaborn green.  \n",
    "    \n",
    "#     Returns:\n",
    "#     ----------\n",
    "#     df_style : df.style\n",
    "\n",
    "#     \"\"\" \n",
    "#     from IPython.display import display  \n",
    "#     import seaborn as sns\n",
    "#     cm = matplotlib_cmap\n",
    "#     #     cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "#     df_style = df.style.background_gradient(cmap=cm,subset=subset)#,low=results.min(),high=results.max())\n",
    "#     # Display styled dataframe\n",
    "# #     display(df_style)\n",
    "#     return df_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_scale_columns(df,\"YlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## James' Tree Classifier/Regressor Testing & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def performance_r2_mse(y_true, y_pred):\n",
    "#     \"\"\" Calculates and returns the performance score between \n",
    "#         true and predicted values based on the metric chosen. \"\"\"\n",
    "#     from sklearn.metrics import r2_score\n",
    "#     from sklearn.metrics import mean_squared_error as mse\n",
    "    \n",
    "#     r2 = r2_score(y_true,y_pred)\n",
    "#     MSE = mse(y_true,y_pred)    \n",
    "#     return r2, MSE\n",
    "\n",
    "# # def performance_roc_auc(X_test,y_test,dtc,verbose=False):\n",
    "# def performance_roc_auc(y_true,y_pred):\n",
    "#     \"\"\"Tests the results of an already-fit classifer. \n",
    "#     Takes y_true (test split), and y_pred (model.predict()), returns the AUC for the roc_curve as a %\"\"\"\n",
    "#     from sklearn.metrics import roc_curve, auc\n",
    "#     FP_rate, TP_rate, _ = roc_curve(y_true,y_pred)\n",
    "#     roc_auc = auc(FP_rate,TP_rate)\n",
    "#     roc_auc_perc = round(roc_auc*100,3)\n",
    "#     return roc_auc_perc\n",
    "\n",
    "# def tune_params_trees(param_name, param_values, DecisionTreeObject, X,Y,test_size=0.25,perform_metric='r2_mse'):\n",
    "#     '''Takes a parame_name (str), param_values (list/array), a DecisionTreeObject, and a perform_metric.\n",
    "#     Loops through the param_values and re-fits the model and saves performance metrics. Displays color-mapped dataframe of results and line graph.\n",
    "    \n",
    "#     Perform_metric can be 'r2_mse' or 'roc_auc'.\n",
    "#     Returns:\n",
    "#     - df of results\n",
    "#     - styled-df'''\n",
    "\n",
    "#     from sklearn.model_selection import train_test_split\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(test_size=test_size)\n",
    "\n",
    "#     # Create results depending on performance metric\n",
    "#     if perform_metric=='r2_mse':\n",
    "#         results = [['param_name','param_value','r2_test','MSE_test']]\n",
    "        \n",
    "#     elif perform_metric=='roc_auc':\n",
    "#         results =  [['param_name','param_value','roc_auc_test']]\n",
    "#     print(f'Using performance metrics: {perform_metric}')\n",
    "    \n",
    "#     # Rename Deicision Tree for looping\n",
    "#     dtr_tune =  DecisionTreeObject\n",
    "    \n",
    "#     # Loop through each param_value\n",
    "#     for value in param_values:\n",
    "\n",
    "#         # Set the parameters and fit the model\n",
    "#         dtr_tune.set_params(**{param_name:value})\n",
    "#         dtr_tune.fit(X_train,y_train)\n",
    "\n",
    "#         # Get predicitons and test_performance\n",
    "#         y_preds = dtr_tune.predict(X_test)\n",
    "        \n",
    "#         # Perform correct performance metric and append results\n",
    "#         if perform_metric=='r2_mse':\n",
    "            \n",
    "#             r2_test, mse_test = performance_r2_mse(y_test,y_preds)\n",
    "#             results.append([param_name,value,r2_test,mse_test])\n",
    "        \n",
    "#         elif perform_metric=='roc_auc':\n",
    "            \n",
    "#             roc_auc_test = performance_roc_auc(y_test,y_preds)\n",
    "#             results.append([param_name,value,roc_auc_test])\n",
    "     \n",
    "\n",
    "#     # Convert results to dataframe, set index\n",
    "#     df_results = list2df(results)\n",
    "#     df_results.set_index('param_value',inplace=True)\n",
    "\n",
    "\n",
    "#     # Plot the values in results\n",
    "#     df_results.plot(subplots=True,sharex=True)\n",
    "\n",
    "#     # Style dataframe for easy visualization\n",
    "#     import seaborn as sns\n",
    "#     cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "#     df_style = df_results.style.background_gradient(cmap=cm,subset=['r2_test','MSE_test'])#,low=results.min(),high=results.max())\n",
    "#     # Display styled dataframe\n",
    "#     from IPython.display import display  \n",
    "#     display(df_style)\n",
    "    \n",
    "#     return df_results\n",
    "\n",
    "\n",
    "\n",
    "# def viz_tree(tree_object):\n",
    "#     '''Takes a Sklearn Decision Tree and returns a png image using graph_viz and pydotplus.'''\n",
    "#     # Visualize the decision tree using graph viz library \n",
    "#     from sklearn.externals.six import StringIO  \n",
    "#     from IPython.display import Image  \n",
    "#     from sklearn.tree import export_graphviz\n",
    "#     import pydotplus\n",
    "#     dot_data = StringIO()\n",
    "#     export_graphviz(tree_object, out_file=dot_data, filled=True, rounded=True,special_characters=True)\n",
    "#     graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "#     tree_viz = Image(graph.create_png())\n",
    "#     return tree_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection and Stats tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's method using IQR to eliminate \n",
    "def detect_outliers(df, n, features):\n",
    "    \"\"\"Uses Tukey's method to return outer of interquartile ranges to return indices if outliers in a dataframe.\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing columns of features\n",
    "    n: default is 0, multiple outlier cutoff  \n",
    "    \n",
    "    Returns:\n",
    "    Index of outliers for .loc\n",
    "    \n",
    "    Examples:\n",
    "    Outliers_to_drop = detect_outliers(data,2,[\"col1\",\"col2\"]) Returning value\n",
    "    df.loc[Outliers_to_drop] # Show the outliers rows\n",
    "    data= data.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)\n",
    "\"\"\"\n",
    "\n",
    "# Drop outliers    \n",
    "\n",
    "    outlier_indices = []\n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        \n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        \n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "        # select observations containing more than 2 outliers\n",
    "        from collections import Counter\n",
    "        outlier_indices = Counter(outlier_indices)        \n",
    "        multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    return multiple_outliers \n",
    "\n",
    "\n",
    "def find_outliers(column):\n",
    "    quartile_1, quartile_3 = np.percentile(column, [25, 75])\n",
    "    IQR = quartile_3 - quartile_1\n",
    "    low_outlier = quartile_1 - (IQR * 1.5)\n",
    "    high_outlier = quartile_3 + (IQR * 1.5)    \n",
    "    outlier_index = column[(column < low_outlier) | (column > high_outlier)].index\n",
    "    return outlier_index\n",
    "\n",
    "# describe_outliers -- calls find_outliers\n",
    "def describe_outliers(df):\n",
    "    \"\"\" Returns a new_df of outliers, and % outliers each col using detect_outliers.\n",
    "    \"\"\"\n",
    "    out_count = 0\n",
    "    new_df = pd.DataFrame(columns=['total_outliers', 'percent_total'])\n",
    "    for col in df.columns:\n",
    "        outies = find_outliers(df[col])\n",
    "        out_count += len(outies) \n",
    "        new_df.loc[col] = [len(outies), round((len(outies)/len(df.index))*100, 2)]\n",
    "    new_df.loc['grand_total'] = [sum(new_df['total_outliers']), sum(new_df['percent_total'])]\n",
    "    return new_df\n",
    "\n",
    "\n",
    "#### Cohen's d\n",
    "def Cohen_d(group1, group2):\n",
    "    '''Compute Cohen's d.\n",
    "    # group1: Series or NumPy array\n",
    "    # group2: Series or NumPy array\n",
    "    # returns a floating point number \n",
    "    '''\n",
    "    diff = group1.mean() - group2.mean()\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1 = group1.var()\n",
    "    var2 = group2.var()\n",
    "\n",
    "    # Calculate the pooled threshold as shown earlier\n",
    "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "    \n",
    "    # Calculate Cohen's d statistic\n",
    "    d = diff / np.sqrt(pooled_var)\n",
    "    \n",
    "    return d\n",
    "\n",
    "## commented out due to missing evaluate_PDF function\n",
    "# def plot_pdfs(cohen_d=2):\n",
    "#     \"\"\"Plot PDFs for distributions that differ by some number of stds.\n",
    "    \n",
    "#     cohen_d: number of standard deviations between the means\n",
    "#     \"\"\"\n",
    "#     import scipy \n",
    "#     group1 = scipy.stats.norm(0, 1)\n",
    "#     group2 = scipy.stats.norm(cohen_d, 1)\n",
    "#     xs, ys = evaluate_PDF(group1)\n",
    "#     pyplot.fill_between(xs, ys, label='Group1', color='#ff2289', alpha=0.7)\n",
    "\n",
    "#     xs, ys = evaluate_PDF(group2)\n",
    "#     pyplot.fill_between(xs, ys, label='Group2', color='#376cb0', alpha=0.7)\n",
    "    \n",
    "#     o, s = overlap_superiority(group1, group2)\n",
    "#     print('overlap', o)\n",
    "#     print('superiority', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mike's Plotting Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### MIKE's PLOTTING\n",
    "# # plotting order totals per month in violin plots\n",
    "\n",
    "# def draw_violinplot(x , y, hue=None, data=None, title=None,\n",
    "#                     ticklabels=None, leg_label=None):\n",
    "    \n",
    "#     '''Plots a violin plot with horizontal mean line, inner stick lines\n",
    "#     y must be arraylike in order to plot mean line. x can be label in data'''\n",
    "\n",
    "    \n",
    "#     fig,ax = plt.subplots(figsize=(12,10))\n",
    "\n",
    "#     sns.violinplot(x, y, hue=hue,\n",
    "#                    data = data,\n",
    "#                    cut=2,\n",
    "#                    split=True, \n",
    "#                    scale='count',\n",
    "#                    scale_hue=True,\n",
    "#                    saturation=.7,\n",
    "#                    alpha=.9, \n",
    "#                    bw=.25,\n",
    "#                    palette='Dark2',\n",
    "#                    inner='stick'\n",
    "#                   ).set_title(title)\n",
    "    \n",
    "#     ax.set(xlabel= x.name.title(),\n",
    "#           ylabel= y.name.title(),\n",
    "#            xticklabels=ticklabels)\n",
    "    \n",
    "#     ax.axhline( y.mean(),\n",
    "#                label='Total Mean',\n",
    "#                ls=':',\n",
    "#                alpha=.2, \n",
    "#                color='xkcd:yellow')\n",
    "    \n",
    "#     ax.legend().set_title(leg_label)\n",
    "\n",
    "#     plt.show()\n",
    "#     return fig, ax\n",
    "\n",
    "# #####\n",
    "# def subplot_imshow(images, num_images,num_rows, num_cols, figsize=(20,15)):\n",
    "#     '''\n",
    "#     Takes image data and plots a figure with subplots for as many images as given.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     images: str, data in form data.images ie. olivetti images\n",
    "#     num_images: int, number of images\n",
    "#     num_rows: int, number of rows to plot.\n",
    "#     num_cols: int, number of columns to plot\n",
    "#     figize: tuple, size of figure default=(20,15)\n",
    "    \n",
    "#     returns:  figure with as many subplots as images given\n",
    "#     '''\n",
    "\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     fig = plt.figure(figsize=figsize)\n",
    "#     for i in range(num_images):\n",
    "#         ax = fig.add_subplot(num_rows,num_cols, i+1, xticks=[], yticks=[])\n",
    "#         ax.imshow(images[i],cmap=plt.gray)\n",
    "        \n",
    "#     plt.show()\n",
    "    \n",
    "#     return fig, ax\n",
    "# #####\n",
    "# ###########\n",
    "# def plot_wide_kde_thin_bar(series1,sname1, series2, sname2):\n",
    "#     '''Plot series1 and series 2 on wide kde plot with small mean+sem bar plot.'''\n",
    "    \n",
    "#     ## ADDING add_gridspec usage\n",
    "#     import pandas as pd\n",
    "#     import numpy as np\n",
    "#     from scipy.stats import sem\n",
    "\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import matplotlib as mpl\n",
    "#     import matplotlib.ticker as ticker\n",
    "\n",
    "#     import seaborn as sns\n",
    "\n",
    "#     from matplotlib import rcParams\n",
    "#     from matplotlib import rc\n",
    "#     rcParams['font.family'] = 'serif'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # Plot distributions of discounted vs full price groups\n",
    "#     plt.style.use('default')\n",
    "#     # with plt.style.context(('tableau-colorblind10')):\n",
    "#     with plt.style.context(('seaborn-notebook')):\n",
    "\n",
    "        \n",
    "\n",
    "#         ## ----------- DEFINE AESTHETIC CUSTOMIZATIONS ----------- ##\n",
    "#        # Axis Label fonts\n",
    "#         fontSuptitle ={'fontsize': 22,\n",
    "#                    'fontweight': 'bold',\n",
    "#                     'fontfamily':'serif'}\n",
    "\n",
    "#         fontTitle = {'fontsize': 10,\n",
    "#                    'fontweight': 'medium',\n",
    "#                     'fontfamily':'serif'}\n",
    "\n",
    "#         fontAxis = {'fontsize': 10,\n",
    "#                    'fontweight': 'medium',\n",
    "#                     'fontfamily':'serif'}\n",
    "\n",
    "#         fontTicks = {'fontsize': 8,\n",
    "#                    'fontweight':'medium', \n",
    "#                     'fontfamily':'serif'}\n",
    "\n",
    "\n",
    "#         ## --------- CREATE FIG BASED ON GRIDSPEC --------- ##\n",
    "        \n",
    "#         plt.suptitle('Quantity of Units Sold', fontdict = fontSuptitle)\n",
    "\n",
    "#         # Create fig object and declare figsize\n",
    "#         fig = plt.figure(constrained_layout=True, figsize=(8,3))\n",
    "        \n",
    "        \n",
    "#         # Define gridspec to create grid coordinates             \n",
    "#         gs = fig.add_gridspec(nrows=1,ncols=10)\n",
    "\n",
    "#         # Assign grid space to ax with add_subplot\n",
    "#         ax0 = fig.add_subplot(gs[0,0:7])\n",
    "#         ax1 = fig.add_subplot(gs[0,7:10])\n",
    "        \n",
    "#         #Combine into 1 list\n",
    "#         ax = [ax0,ax1]\n",
    "        \n",
    "#         ### ------------------  SUBPLOT 1  ------------------ ###\n",
    "\n",
    "#         ## --------- Defining series1 and 2 for subplot 1------- ##\n",
    "#         ax[0].set_title('Histogram + KDE',fontdict=fontTitle)\n",
    "\n",
    "#         # Group 1: data, label, hist_kws and kde_kws\n",
    "#         plotS1 = {'data': series1, 'label': sname1.title(),\n",
    "\n",
    "#                    'hist_kws' :\n",
    "#                     {'edgecolor': 'black', 'color':'darkgray','alpha': 0.8, 'lw':0.5},\n",
    "\n",
    "#                    'kde_kws':\n",
    "#                     {'color':'gray', 'linestyle': '--', 'linewidth':2,\n",
    "#                      'label':'kde'}}\n",
    "\n",
    "#         # Group 2: data, label, hist_kws and kde_kws\n",
    "#         plotS2 = {'data': series2,\n",
    "#                     'label': sname2.title(), \n",
    "\n",
    "#                     'hist_kws' :\n",
    "#                     {'edgecolor': 'black','color':'green','alpha':0.8 ,'lw':0.5},\n",
    "\n",
    "\n",
    "#                     'kde_kws':\n",
    "#                     {'color':'darkgreen','linestyle':':','linewidth':3,'label':'kde'}}\n",
    "        \n",
    "#         # plot group 1\n",
    "#         sns.distplot(plotS1['data'], label=plotS1['label'],\n",
    "                   \n",
    "#                      hist_kws = plotS1['hist_kws'], kde_kws = plotS1['kde_kws'],\n",
    "                     \n",
    "#                      ax=ax[0])   \n",
    "      \n",
    "\n",
    "#         # plot group 2\n",
    "#         sns.distplot(plotS2['data'], label=plotS2['label'],\n",
    "                     \n",
    "#                      hist_kws=plotS2['hist_kws'], kde_kws = plotS2['kde_kws'],\n",
    "                     \n",
    "#                      ax=ax[0])\n",
    "\n",
    "\n",
    "#         ax[0].set_xlabel(series1.name, fontdict=fontAxis)\n",
    "#         ax[0].set_ylabel('Kernel Density Estimation',fontdict=fontAxis)\n",
    "\n",
    "#         ax[0].tick_params(axis='both',labelsize=fontTicks['fontsize'])   \n",
    "#         ax[0].legend()\n",
    "\n",
    "\n",
    "#         ### ------------------  SUBPLOT 2  ------------------ ###\n",
    "        \n",
    "#         # Import scipy for error bars\n",
    "#         from scipy.stats import sem\n",
    "    \n",
    "#         # Declare x y group labels(x) and bar heights(y)\n",
    "#         x = [plotS1['label'], plotS2['label']]\n",
    "#         y = [np.mean(plotS1['data']), np.mean(plotS2['data'])]\n",
    "\n",
    "#         yerr = [sem(plotS1['data']), sem(plotS2['data'])]\n",
    "#         err_kws = {'ecolor':'black','capsize':5,'capthick':1,'elinewidth':1}\n",
    "\n",
    "#         # Create the bar plot\n",
    "#         ax[1].bar(x,y,align='center', edgecolor='black', yerr=yerr,error_kw=err_kws,width=0.6)\n",
    "\n",
    "        \n",
    "#         # Customize subplot 2\n",
    "#         ax[1].set_title('Average Quantities Sold',fontdict=fontTitle)\n",
    "#         ax[1].set_ylabel('Mean +/- SEM ',fontdict=fontAxis)\n",
    "#         ax[1].set_xlabel('')\n",
    "        \n",
    "#         ax[1].tick_params(axis=y,labelsize=fontTicks['fontsize'])\n",
    "#         ax[1].tick_params(axis=x,labelsize=fontTicks['fontsize']) \n",
    "\n",
    "#         ax1=ax[1]\n",
    "#         test = ax1.get_xticklabels()\n",
    "#         labels = [x.get_text() for x in test]\n",
    "#         ax1.set_xticklabels([plotS1['label'],plotS2['label']], rotation=45,ha='center')\n",
    "        \n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "#         return fig,ax\n",
    "\n",
    "\n",
    "# def scale_data(data, method='minmax', log=False):\n",
    "    \n",
    "#     \"\"\"Takes df or Series, scales it using desired method and returns scaled df.\n",
    "    \n",
    "#     Parameters\n",
    "#     -----------\n",
    "#     data : pd.Series or pd.DataFrame\n",
    "#         entire dataframe of series to be scaled\n",
    "#     method : str\n",
    "#         The method for scaling to be implemented(default is 'minmax').\n",
    "#         Other options are 'standard' or 'robust'.\n",
    "#     log : bool, optional\n",
    "#         Takes log of data if set to True(deafault is False).\n",
    "        \n",
    "#     Returns\n",
    "#     --------\n",
    "#     pd.DataFrame of scaled data.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     import pandas as pd\n",
    "#     import numpy as np\n",
    "#     from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "    \n",
    "#     scale = np.array(data)\n",
    "    \n",
    "#     # reshape if needed\n",
    "#     if len(scale.shape) == 1:\n",
    "#         scale = scale.reshape(-1,1)\n",
    "        \n",
    "#     # takes log if log=True  \n",
    "#     if log == True:\n",
    "#         scale = np.log(scale)\n",
    "        \n",
    "        \n",
    "#     # creates chosen scaler instance\n",
    "#     if method == 'robust':\n",
    "#         scaler = RobustScaler()\n",
    "        \n",
    "#     elif method == 'standard':\n",
    "#         scaler = StandardScaler()\n",
    "        \n",
    "#     else:\n",
    "#         scaler = MinMaxScaler()   \n",
    "#     scaled = scaler.fit_transform(scale)\n",
    "    \n",
    "    \n",
    "#     # reshape and create output DataFrame\n",
    "#     if  scaled.shape[1] > 1:\n",
    "#         df_scaled = pd.DataFrame(scaled, index=data.index, columns=data.columns)\n",
    "        \n",
    "#     else:\n",
    "#         scaled = np.squeeze(scaled)\n",
    "#         scaled = pd.Series(scaled, name=data.name) \n",
    "#         df_scaled = pd.DataFrame(scaled, index=data.index)\n",
    "        \n",
    "#     return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def select_pca(features, n_components_list):\n",
    "    \n",
    "#     '''\n",
    "#     Takes features and list of n_components to run PCA on\n",
    "    \n",
    "#     Params:\n",
    "#     ----------\n",
    "#     features: pd.Dataframe\n",
    "#     n_components: list of ints to pass to PCA n_component parameter\n",
    "    \n",
    "#     returns:\n",
    "#     ----------\n",
    "#     pd.DataFrame, displays number of components and their respective \n",
    "#     explained variance ratio\n",
    "#     '''\n",
    "    \n",
    "#     from JMI_MVM import list2df\n",
    "#     from sklearn.decomposition import PCA\n",
    "    \n",
    "#     # Create list to store results in\n",
    "#     results = [['Model','n_components', 'Explained_Variance_ratio_']]\n",
    "    \n",
    "#     # Loop through list of components to do PCA on\n",
    "#     for n in n_components_list:\n",
    "        \n",
    "#         # Creat instance of PCA class\n",
    "#         pca = PCA(n_components=n)\n",
    "#         pca.fit_transform(features)\n",
    "        \n",
    "#         # Create list of n_component and Explained Variance\n",
    "#         component_variance = ['PCA',n, np.sum(pca.explained_variance_ratio_)]\n",
    "        \n",
    "#         # Append list results list\n",
    "#         results.append(component_variance)\n",
    "        \n",
    "#         # Use list2df to display results in DataFrame\n",
    "#     return list2df(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
